{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN52x2k206MU1JHYq1vli2K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SANGRAMLEMBE/MTech/blob/main/Machine_Learning_Algorithm/Practical/KNN_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN_assignment\n",
        "\n",
        "# Step 1: Data Loading and Preprocessing"
      ],
      "metadata": {
        "id": "stSEDxpCpJpw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries\n"
      ],
      "metadata": {
        "id": "xOlsOPmGpj30"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rLD7czaikd5k"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "717ee772"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your CSV file\n",
        "file_path = '/content/loan_default.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())  # Check the first few rows\n",
        "print(df.info())  # Get a summary of the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjbfQWBCuWzx",
        "outputId": "938533d8-991a-4c18-d30e-7e4932c0d624"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Income  LoanAmount  CreditScore  Defaulted\n",
            "0  11472     30483.0        420.0        0.0\n",
            "1   5727         NaN        751.0        1.0\n",
            "2  15732     23763.0        428.0        1.0\n",
            "3   6958         NaN        390.0        1.0\n",
            "4   2524     16733.0        328.0        1.0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 205 entries, 0 to 204\n",
            "Data columns (total 4 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Income       196 non-null    object \n",
            " 1   LoanAmount   194 non-null    float64\n",
            " 2   CreditScore  194 non-null    float64\n",
            " 3   Defaulted    194 non-null    float64\n",
            "dtypes: float64(3), object(1)\n",
            "memory usage: 6.5+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning\n",
        "\n",
        "- SimpleImputer: This is a tool from the scikit-learn library designed specifically for handling missing values.\n",
        "\n",
        "- Any remaining missing values(NaN) are filled using the median of their respective columns. The median is a good choice as it is robust to outliers."
      ],
      "metadata": {
        "id": "-Jyf9tUeqegL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'error' with NaN\n",
        "df.replace('error', np.nan, inplace=True)\n",
        "\n",
        "# Handle missing values using Median Imputation\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# .fit() : learns what value to use for each column's missing cells.\n",
        "# .transform(): In DataFrame, it replaces all the missing values (like NaN or empty cells) with the medians\n",
        "# .fit_transform : returns the data as a NumPy array\n",
        "# pd.DataFrame(...) to convert it back into a pandas DataFrame.\n",
        "\n",
        "print(\"\\nDataFrame info after imputation:\")\n",
        "df_imputed.info()\n",
        "print(\"\\nDataFrame head after imputation:\")\n",
        "print(df_imputed.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOlFkwqWunQ3",
        "outputId": "64693354-97fb-48b2-d677-42773c8d484c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame info after imputation:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 205 entries, 0 to 204\n",
            "Data columns (total 4 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Income       205 non-null    float64\n",
            " 1   LoanAmount   205 non-null    float64\n",
            " 2   CreditScore  205 non-null    float64\n",
            " 3   Defaulted    205 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 6.5 KB\n",
            "\n",
            "DataFrame head after imputation:\n",
            "    Income  LoanAmount  CreditScore  Defaulted\n",
            "0  11472.0     30483.0        420.0        0.0\n",
            "1   5727.0     22971.5        751.0        1.0\n",
            "2  15732.0     23763.0        428.0        1.0\n",
            "3   6958.0     22971.5        390.0        1.0\n",
            "4   2524.0     16733.0        328.0        1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Data Splitting\n",
        "- The dataset is split into features (X) and the target variable (y). In this case, Defaulted is the target you want to predict.\n",
        "\n",
        "- The data is then divided into a training set (80%) and a testing set (20%). The model will learn from the training set and be evaluated on the unseen testing set.\n",
        "\n",
        "- Feature scaling is applied using StandardScaler to standardize the feature values. This is important for both Logistic Regression and especially for KNN, which is a distance-based algorithm"
      ],
      "metadata": {
        "id": "pf_3d-NzrdDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_imputed[['Income', 'LoanAmount', 'CreditScore']]\n",
        "y = df_imputed['Defaulted']\n"
      ],
      "metadata": {
        "id": "-XAL3IQzvOIz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split"
      ],
      "metadata": {
        "id": "TKe0YBWpy4I6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Add stratify=y\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zclhK1e0rfim"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_kVqINNyFD3",
        "outputId": "ca16ccc6-2c46-433a-e5ce-d668428dc531"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (164, 3)\n",
            "X_test shape: (41, 3)\n",
            "y_train shape: (164,)\n",
            "y_test shape: (41,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scale the features"
      ],
      "metadata": {
        "id": "OEGb74QYyLQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "r-_mNHjZyJtu"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Model Training and Prediction\n",
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "7Jb30LyysYa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "log_reg = LogisticRegression(random_state=42, class_weight='balanced')\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "y_pred_log_reg = log_reg.predict(X_test_scaled)\n"
      ],
      "metadata": {
        "id": "LmmnnD_-zKrL"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## K-Nearest Neighbors (KNN)"
      ],
      "metadata": {
        "id": "gpRL639y0YQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "y_pred_knn = knn.predict(X_test_scaled)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iSIESIT0rlkM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Model Evaluation and Comparison\n"
      ],
      "metadata": {
        "id": "zLeh0bRfvctZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Logistic Regression Evaluation ---\n",
        "print(\"\\n--- Logistic Regression Metrics ---\")\n",
        "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
        "precision_log_reg = precision_score(y_test, y_pred_log_reg, average='weighted')  # Our target variable Defaulted is not strictly binary (0 or 1), so we have to use Weighted\n",
        "recall_log_reg = recall_score(y_test, y_pred_log_reg, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_log_reg:.4f}\")\n",
        "print(f\"Precision: {precision_log_reg:.4f}\")\n",
        "print(f\"Recall: {recall_log_reg:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_log_reg, zero_division=0))\n",
        "\n",
        "\n",
        "# --- KNN Evaluation ---\n",
        "print(\"\\n--- KNN Metrics ---\")\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "precision_knn = precision_score(y_test, y_pred_knn, average='weighted')\n",
        "recall_knn = recall_score(y_test, y_pred_knn, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_knn:.4f}\")\n",
        "print(f\"Precision: {precision_knn:.4f}\")\n",
        "print(f\"Recall: {recall_knn:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_knn, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYogRypDsba3",
        "outputId": "3d14e1bd-41a3-429a-cf56-07eb5aed7f1d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Logistic Regression Metrics ---\n",
            "Accuracy: 0.4878\n",
            "Precision: 0.5017\n",
            "Recall: 0.4878\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.67      0.53        18\n",
            "         1.0       0.57      0.36      0.44        22\n",
            "        10.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.49        41\n",
            "   macro avg       0.34      0.34      0.33        41\n",
            "weighted avg       0.50      0.49      0.47        41\n",
            "\n",
            "\n",
            "--- KNN Metrics ---\n",
            "Accuracy: 0.5854\n",
            "Precision: 0.5706\n",
            "Recall: 0.5854\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.58      0.39      0.47        18\n",
            "         1.0       0.59      0.77      0.67        22\n",
            "        10.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.59        41\n",
            "   macro avg       0.39      0.39      0.38        41\n",
            "weighted avg       0.57      0.59      0.56        41\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nN_MJrs_vfMM"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}