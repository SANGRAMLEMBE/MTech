{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "---\n**These materials are created by Prof. Ramesh Babu exclusively for M.Tech Students of SRM University**\n\n¬© 2025 Prof. Ramesh Babu. All rights reserved. This material is protected by copyright and may not be reproduced, distributed, or transmitted in any form or by any means without prior written permission.\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# T3-Exercise-1: Tensor Fundamentals\n",
    "**Deep Neural Network Architectures (21CSE558T) - Week 2, Day 4**  \n",
    "**M.Tech Lab Session - Duration: 30-45 minutes**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ LEARNING OBJECTIVES\n",
    "By the end of this exercise, you will:\n",
    "- Understand what tensors are and why they're fundamental to neural networks\n",
    "- Create different types of tensors (scalars, vectors, matrices, higher-dimensional)\n",
    "- Master tensor properties: shape, rank, dtype, and size\n",
    "- Apply basic tensor manipulations like reshaping and type conversion\n",
    "\n",
    "## üîó CONNECTION TO NEURAL NETWORKS\n",
    "Think of tensors as the \"language\" of neural networks:\n",
    "- **Input data** (images, text) ‚Üí Tensors\n",
    "- **Weights and biases** ‚Üí Tensors  \n",
    "- **Activations and outputs** ‚Üí Tensors\n",
    "- **All mathematical operations** happen on tensors\n",
    "\n",
    "**Real Example:** A 28√ó28 grayscale image becomes a tensor of shape (28, 28, 1).  \n",
    "When we flatten it for a neural network, it becomes shape (784,)\n",
    "\n",
    "## üìö PREREQUISITES\n",
    "- Basic Python programming\n",
    "- Understanding of arrays/lists\n",
    "- Basic linear algebra (vectors, matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## ‚öôÔ∏è SETUP SECTION\n",
    "Let's start by setting up our environment and checking everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_code"
   },
   "outputs": [],
   "source": [
    "# Essential imports for this exercise\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Environment verification\n",
    "print(\"üîß ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"‚úÖ TensorFlow version: {tf.__version__}\")\n",
    "print(f\"‚úÖ NumPy version: {np.__version__}\")\n",
    "print(f\"‚úÖ Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check if GPU is available (informational only)\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"üöÄ GPU acceleration available\")\n",
    "else:\n",
    "    print(\"üíª Running on CPU (perfectly fine for learning)\")\n",
    "\n",
    "print(\"\\nüéâ Environment ready! Let's start learning about tensors.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "concepts"
   },
   "source": [
    "## üß† CORE CONCEPTS: What Are Tensors?\n",
    "\n",
    "### SIMPLE EXPLANATION:\n",
    "A tensor is just a container for numbers, but organized in a specific way:\n",
    "\n",
    "- **Scalar (0D tensor):** Just one number ‚Üí `42`\n",
    "- **Vector (1D tensor):** A list of numbers ‚Üí `[1, 2, 3]`  \n",
    "- **Matrix (2D tensor):** A table of numbers ‚Üí `[[1, 2], [3, 4]]`\n",
    "- **3D+ tensors:** Multiple matrices stacked together\n",
    "\n",
    "### NEURAL NETWORK ANALOGY:\n",
    "- **Scalar:** A single pixel intensity\n",
    "- **Vector:** A row of pixels, or neuron activations in a layer\n",
    "- **Matrix:** An entire grayscale image, or layer weights\n",
    "- **3D tensor:** Color image (height √ó width √ó channels)\n",
    "- **4D tensor:** Batch of color images (batch √ó height √ó width √ó channels)\n",
    "\n",
    "### WHY TENSORS MATTER:\n",
    "1. **Efficient computation** (vectorization)\n",
    "2. **GPU acceleration**\n",
    "3. **Automatic differentiation** (backpropagation)\n",
    "4. **Consistent interface** for all data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1_title"
   },
   "source": [
    "## üìç STEP 1: Creating Different Types of Tensors\n",
    "Let's create tensors step by step and understand each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step1_scalar"
   },
   "outputs": [],
   "source": [
    "# Creating a SCALAR tensor (0D - just one number)\n",
    "print(\"Creating a SCALAR tensor (0D - just one number):\")\n",
    "scalar = tf.constant(42)\n",
    "print(f\"Scalar tensor: {scalar}\")\n",
    "print(f\"Value: {scalar.numpy()}\")\n",
    "print(f\"This represents: A single value (like one pixel intensity)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step1_vector"
   },
   "outputs": [],
   "source": [
    "# Creating a VECTOR tensor (1D - list of numbers)\n",
    "print(\"Creating a VECTOR tensor (1D - list of numbers):\")\n",
    "vector = tf.constant([1, 2, 3, 4, 5])\n",
    "print(f\"Vector tensor: {vector}\")\n",
    "print(f\"Values: {vector.numpy()}\")\n",
    "print(f\"This represents: One row of pixels, or activations from 5 neurons\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step1_matrix"
   },
   "outputs": [],
   "source": [
    "# Creating a MATRIX tensor (2D - table of numbers)\n",
    "print(\"Creating a MATRIX tensor (2D - table of numbers):\")\n",
    "matrix = tf.constant([[1, 2, 3], \n",
    "                      [4, 5, 6]])\n",
    "print(f\"Matrix tensor:\\n{matrix}\")\n",
    "print(f\"Values:\\n{matrix.numpy()}\")\n",
    "print(f\"This represents: A small grayscale image patch (2√ó3 pixels)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step1_3d"
   },
   "outputs": [],
   "source": [
    "# Creating a 3D tensor (like a color image)\n",
    "print(\"Creating a 3D tensor (like a color image):\")\n",
    "tensor_3d = tf.constant([[[1, 2], [3, 4]], \n",
    "                         [[5, 6], [7, 8]]])\n",
    "print(f\"3D tensor:\\n{tensor_3d}\")\n",
    "print(f\"This represents: A tiny 2√ó2 color image with 2 channels\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2_title"
   },
   "source": [
    "## üìç STEP 2: Understanding Tensor Properties\n",
    "Let's examine each tensor's properties to understand what they mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step2_properties"
   },
   "outputs": [],
   "source": [
    "# Let's examine each tensor's properties\n",
    "tensors_to_examine = [\n",
    "    (\"Scalar\", scalar, \"Single number\"),\n",
    "    (\"Vector\", vector, \"List of 5 numbers\"), \n",
    "    (\"Matrix\", matrix, \"2√ó3 table\"),\n",
    "    (\"3D Tensor\", tensor_3d, \"2√ó2√ó2 cube\")\n",
    "]\n",
    "\n",
    "for name, tensor, description in tensors_to_examine:\n",
    "    print(f\"\\nüîç Examining {name} ({description}):\")\n",
    "    print(f\"  üìè Shape: {tensor.shape} ‚Üê Dimensions of the tensor\")\n",
    "    print(f\"  üìä Rank: {tf.rank(tensor).numpy()} ‚Üê Number of dimensions\")\n",
    "    print(f\"  üè∑Ô∏è  Data type: {tensor.dtype} ‚Üê Type of numbers stored\")\n",
    "    print(f\"  üì¶ Total size: {tf.size(tensor).numpy()} ‚Üê Total number of elements\")\n",
    "    \n",
    "    # Help students understand what shape means\n",
    "    if tensor.shape.ndims == 0:\n",
    "        print(\"     Shape () means: No dimensions, just one value\")\n",
    "    elif tensor.shape.ndims == 1:\n",
    "        print(f\"     Shape ({tensor.shape[0]},) means: {tensor.shape[0]} elements in a line\")\n",
    "    elif tensor.shape.ndims == 2:\n",
    "        print(f\"     Shape ({tensor.shape[0]}, {tensor.shape[1]}) means: {tensor.shape[0]} rows, {tensor.shape[1]} columns\")\n",
    "    elif tensor.shape.ndims == 3:\n",
    "        print(f\"     Shape ({tensor.shape[0]}, {tensor.shape[1]}, {tensor.shape[2]}) means: {tensor.shape[0]} matrices of {tensor.shape[1]}√ó{tensor.shape[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3_title"
   },
   "source": [
    "## üìç STEP 3: Special Ways to Create Tensors\n",
    "Neural networks often need tensors with specific patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step3_zeros"
   },
   "outputs": [],
   "source": [
    "# Creating tensors filled with ZEROS (common for initializing bias)\n",
    "print(\"Creating tensors filled with ZEROS (common for initializing bias):\")\n",
    "zeros_matrix = tf.zeros((3, 4))\n",
    "print(f\"3√ó4 matrix of zeros:\\n{zeros_matrix}\")\n",
    "print(\"üí° Use case: Initializing bias vectors in neural networks\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step3_ones"
   },
   "outputs": [],
   "source": [
    "# Creating tensors filled with ONES\n",
    "print(\"Creating tensors filled with ONES:\")\n",
    "ones_vector = tf.ones(5)\n",
    "print(f\"Vector of 5 ones: {ones_vector}\")\n",
    "print(\"üí° Use case: Creating masks or initialization\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step3_random"
   },
   "outputs": [],
   "source": [
    "# Creating tensors with RANDOM values (crucial for neural networks)\n",
    "print(\"Creating tensors with RANDOM values (crucial for neural networks):\")\n",
    "random_matrix = tf.random.normal((2, 3), mean=0.0, stddev=1.0)\n",
    "print(f\"2√ó3 matrix with random normal values:\\n{random_matrix}\")\n",
    "print(\"üí° Use case: Initializing weights in neural networks\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step3_variable"
   },
   "outputs": [],
   "source": [
    "# Creating a VARIABLE tensor (weights that can be trained)\n",
    "print(\"Creating a VARIABLE tensor (weights that can be trained):\")\n",
    "trainable_weights = tf.Variable(tf.random.normal((2, 3), stddev=0.1), name=\"layer_weights\")\n",
    "print(f\"Trainable weights:\\n{trainable_weights}\")\n",
    "print(\"üí° Use case: Neural network weights that update during training\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4_title"
   },
   "source": [
    "## üìç STEP 4: Reshaping Tensors (Very Important!)\n",
    "üéØ Reshaping is crucial when connecting different layers in neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step4_original"
   },
   "outputs": [],
   "source": [
    "# Start with a sample data tensor\n",
    "original_data = tf.constant([[1, 2, 3, 4], \n",
    "                            [5, 6, 7, 8]])\n",
    "print(f\"Original data {original_data.shape}:\")\n",
    "print(original_data)\n",
    "print(\"This could represent: 2 samples, each with 4 features\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step4_flatten"
   },
   "outputs": [],
   "source": [
    "# Flatten to 1D (common when going from CNN to dense layer)\n",
    "print(\"Reshaping to different configurations:\")\n",
    "flattened = tf.reshape(original_data, (-1,))\n",
    "print(f\"Flattened to 1D {flattened.shape}: {flattened}\")\n",
    "print(\"üí° Use case: Flattening image data before dense layer\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step4_column"
   },
   "outputs": [],
   "source": [
    "# Reshape to column vector\n",
    "column_vector = tf.reshape(original_data, (8, 1))\n",
    "print(f\"Reshaped to column vector {column_vector.shape}:\")\n",
    "print(column_vector)\n",
    "print(\"üí° Use case: Preparing data for certain layer types\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step4_batch"
   },
   "outputs": [],
   "source": [
    "# Reshape to 3D (adding batch dimension)\n",
    "batched = tf.reshape(original_data, (1, 2, 4))\n",
    "print(f\"Reshaped to 3D with batch dimension {batched.shape}:\")\n",
    "print(batched)\n",
    "print(\"üí° Use case: Adding batch dimension for neural network input\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5_title"
   },
   "source": [
    "## üìç STEP 5: Working with Different Data Types\n",
    "Understanding data types is important for memory efficiency and computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step5_datatypes"
   },
   "outputs": [],
   "source": [
    "# Integer tensor\n",
    "int_tensor = tf.constant([1, 2, 3], dtype=tf.int32)\n",
    "print(f\"Integer tensor: {int_tensor} (dtype: {int_tensor.dtype})\")\n",
    "\n",
    "# Convert to float\n",
    "float_tensor = tf.cast(int_tensor, tf.float32)\n",
    "print(f\"Converted to float: {float_tensor} (dtype: {float_tensor.dtype})\")\n",
    "\n",
    "# Boolean tensor\n",
    "bool_tensor = tf.constant([True, False, True])\n",
    "print(f\"Boolean tensor: {bool_tensor} (dtype: {bool_tensor.dtype})\")\n",
    "print(\"üí° Use case: Creating masks for selective operations\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validation_title"
   },
   "source": [
    "## ‚úÖ VALIDATION & TESTING\n",
    "Let's test your understanding with a practical example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validation_scenario"
   },
   "outputs": [],
   "source": [
    "print(\"üß† SCENARIO: Processing a batch of 3 images for a neural network\")\n",
    "print()\n",
    "\n",
    "# Simulate 3 grayscale images of size 4√ó4 pixels\n",
    "batch_size = 3\n",
    "height, width = 4, 4\n",
    "input_batch = tf.random.uniform((batch_size, height, width), 0, 255, dtype=tf.float32)\n",
    "\n",
    "print(f\"Input batch shape: {input_batch.shape}\")\n",
    "print(f\"This represents: {batch_size} images, each {height}√ó{width} pixels\")\n",
    "print()\n",
    "\n",
    "# Flatten for dense layer (common operation)\n",
    "flattened_batch = tf.reshape(input_batch, (batch_size, -1))\n",
    "print(f\"Flattened for dense layer: {flattened_batch.shape}\")\n",
    "print(f\"This represents: {batch_size} samples, each with {height*width} features\")\n",
    "print()\n",
    "\n",
    "# Check our work\n",
    "expected_features = height * width\n",
    "actual_features = flattened_batch.shape[1]\n",
    "print(f\"‚úÖ Validation: Expected {expected_features} features, got {actual_features}\")\n",
    "print(f\"‚úÖ Shape check: {actual_features == expected_features}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "takeaways"
   },
   "source": [
    "## üîç KEY TAKEAWAYS\n",
    "\n",
    "1. **Tensors are the fundamental data structure** in neural networks\n",
    "2. **Shape tells you the dimensions:** (batch_size, height, width, channels)\n",
    "3. **Rank is the number of dimensions** (0D=scalar, 1D=vector, 2D=matrix, etc.)\n",
    "4. **Reshaping is crucial** for connecting different types of layers\n",
    "5. **Variables are tensors that can be trained** (weights and biases)\n",
    "6. **Data type affects memory usage** and computation precision\n",
    "7. **Always check tensor shapes** when debugging neural networks\n",
    "\n",
    "### ü§î QUESTIONS TO THINK ABOUT:\n",
    "- How would you represent a batch of 32 color images (28√ó28 pixels)?\n",
    "- What shape would the weights have for a layer with 128 inputs and 64 outputs?\n",
    "- Why do we need to flatten images before feeding them to dense layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_exercise"
   },
   "source": [
    "## ‚û°Ô∏è NEXT EXERCISE PREVIEW\n",
    "\n",
    "### üéØ T3-Exercise-2: Mathematical Operations\n",
    "\n",
    "In the next exercise, you'll learn:\n",
    "- Element-wise operations (addition, multiplication)\n",
    "- Matrix multiplication (the heart of neural networks)\n",
    "- Broadcasting (working with different sized tensors)\n",
    "- Practical applications in neural network computations\n",
    "\n",
    "üí° **Coming up:** We'll see how tensors 'talk' to each other through math!\n",
    "\n",
    "---\n",
    "\n",
    "# üéâ EXERCISE 1 COMPLETED!\n",
    "**You now understand the building blocks of neural networks!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}